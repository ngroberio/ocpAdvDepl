Guide

++ Installation
  First execute the sudo command to ensure that you have operational execution authority, and then clone the prepared script from GitHub to the local environment.
  [xxxx@bastion ~]$ sudo -i
  [root@bastion ~]# git clone https://github.com/ngroberio/ocpAdvDepl
  Then go into the working directory and execute the Ansible playbook script to install the environment. The entire installation will take about an hour.
  [root@bastion ~]# cd ocpAdvDepl

  Than you can run:
    [root@bastion ~]# ansible-playbook ./ansible_deployment_homework.yaml (ansible Installation)
    + OR
    [root@bastion ~]# ./install.sh (bash installation)

++ Uninstallation
  If for any reason you want to clean up your environment run:
  [root@bastion ~]# ./uninstall.sh

++ Deployment Target

Ansible playbook file ansible_deployment_homework.yaml or the script install.sh are the entry point for the installation configuration, which includes all operational tasks.

  Prepare GUID environment variable across all hosts
  Verify Installation and Configuration of Docker
  Verify NFS Shared Volumes on Hosts
  Install packages and config auth
  Generate Inventory Hosts File
  Execute the openshift-ansible prerequisites
  Execute the openshift-ansible Deployer
  Verify OpenShift Cluster
  Post installation configuration
  Create PVs for Users
  Create 25 definitions files for PVs 5G size
  Create 25 definitions files for PVs 10G size
  Create all PVs from definitions files
  Fix NFS Persistent Volume Recycling
  Smoke Test
  CI/CD workflow
  HPA configuration on production deployment of openshift-tasks
  Multitenancy

++ Provisioned Environment Hosts
  This one-click installation script applies to the following host environment.
  Bastion host:
    bastion.$GUID.example.opentlc.com,
    bastion.$GUID.internal
  Load balancer:
    loadbalancer1.$GUID.example.opentlc.com,
    loadbalancer1.$GUID.internal
  3 OpenShift master nodes:
    master{1,2,3}.$GUID.internal
  2 OpenShift infrastructure nodes:
    infranode{1,2}.$GUID.example.opentlc.com,
    infranode{1,2}.$GUID.internal
  4 OpenShift worker nodes:
    node{1-4}.$GUID.internal
  NFS server:
    support1.$GUID.internal

Engagement journal

++ Basic Requirements
  User Amy can log in as administrator on the master console with r3dh4t1! as password.
  Registry console URL is https://registry-console-default.apps.$GUID.example.opentlc.com.
  Master console URL is https://loadbalancer.$GUID.example.opentlc.com
  25 PVs with a size of 5 GB and ReadWriteOnce  access mode have been created.
  25 PVs with a size of 10 GB and ReadWriteMany access mode have been created.
  Create and destroy the nodejs-mongo-persistent application by using smoking test scripts.
  ->These are related shell scripts below:
    ./config/infra/pvs/create_pvs.sh
    ./config/infra/pvs/pvs_5Gsize.sh
    ./config/infra/pvs/pvs_10Gsize.sh
    ./config/bin/nodejs_mongo_smoke_test.sh

++ HA Requirements
  There are three masters working
  There are three etcd instances working
  There is a load balancer to access the masters called loadbalancer1.$GUID.example.opentlc.com
  There is a load balancer/DNS for both infranodes called *.apps.$GUID.example.opentlc.com
  There are at two infranodes, labeled env=infra
  ->These are related templates below:
    ./config/templates/hosts_template.yaml

++ Environment Configuration
  NetworkPolicy is configured and working with projects isolated by default:
    -> os_sdn_network_plugin_name='redhat/openshift-ovs-multitenant'

  Aggregated logging is configured and working
  Metrics collection is configured and working
  Router and Registry Pods run on Infranodes
  Metrics and Logging components run on Infranodes
  Service Catalog, Template Service Broker, and Ansible Service Broker are all working very well.
  -> These are related templates below:
    ./config/templates/hosts_template.yaml

++ CICD Workflow
  Jenkins pod is running with a persistent volume
  Jenkins deploys openshift-tasks app
  Jenkins OpenShift plugin is used to create a CICD workflow
  HPA is configured and working on production deployment of openshift-tasks
  ->These are related templates below:
    ./config/templates/os_pipeline_template.yaml
    ./config/templates/setup_jenkins.yaml
  -> These are install scripts lines related below:
      ./config/infra/setup_cicd.sh

++ Multitenancy
  Alpha Corp group have two users, Amy and Andrew
  Beta Corp group have two users, Brian and Betty
  Dedicated node for each Client:
    -> admissionControl plugin sets specific limits per label (client/customer)

  The new project template is modified so that it includes a LimitRange
  The new user template is used to create a user object with the specific label value
  ->These are related shell scripts and templates below:
    ./config/infra/setup_multitenacy.sh
    ./config/templates/multi_template.yaml
