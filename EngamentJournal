Guide

++ Installation
  First execute the sudo command to ensure that you have operational execution authority, and then clone the prepared script from GitHub to the local environment.
  sudo -i
  git clone https://github.com/ngroberio/ocpAdvDepl
  Then go into the working directory and execute the Ansible playbook script to install the environment. The entire installation will take about an hour.
  cd ocpAdvDepl

  To install you can run:
    ./install_ansible.sh (main installation)

  Also have a bash installation:
   ./install.sh

++ Uninstallation
  If for any reason you want to clean up your environment run:
  ./uninstall.sh

++ Deployment Target

Ansible playbook file ansible_deployment_homework_v2.yaml or the script install.sh are the entry point for the installation configuration, which includes all operational tasks.

  Prepare GUID environment variable across all hosts
  Verify Installation and Configuration of Docker
  Verify NFS Shared Volumes on Hosts
  Install packages and config auth
  Generate Inventory Hosts File
  Execute the openshift-ansible prerequisites
  Execute the openshift-ansible Deployer
  Verify OpenShift Cluster
  Post installation configuration
  Create PVs for Users
  Create 25 definitions files for PVs 5G size
  Create 25 definitions files for PVs 10G size
  Create all PVs from definitions files
  Fix NFS Persistent Volume Recycling
  Smoke Test
  CI/CD workflow
  HPA configuration on production deployment of openshift-tasks
  Multitenancy

++ Provisioned Environment Hosts
  This one-click installation script applies to the following host environment.
  Bastion host:
    bastion.$GUID.example.opentlc.com,
    bastion.$GUID.internal
  Load balancer:
    loadbalancer1.$GUID.example.opentlc.com,
    loadbalancer1.$GUID.internal
  3 OpenShift master nodes:
    master{1,2,3}.$GUID.internal
  2 OpenShift infrastructure nodes:
    infranode{1,2}.$GUID.example.opentlc.com,
    infranode{1,2}.$GUID.internal
  4 OpenShift worker nodes:
    node{1-4}.$GUID.internal
  NFS server:
    support1.$GUID.internal

Engagement journal

++ Basic Requirements
  User amy can log in as administrator on the master console with r3dh4t1! as password.
  Registry console URL is https://registry-console-default.apps.$GUID.example.opentlc.com.
  Master console URL is https://loadbalancer.$GUID.example.opentlc.com
  25 PVs with a size of 5 GB and ReadWriteOnce  access mode have been created.
  25 PVs with a size of 10 GB and ReadWriteMany access mode have been created.
  Create and destroy the nodejs-mongo-persistent application by using smoking test scripts.
  ->These are the ROLES:
    ./roles/7_CREATE_PVS
    ./roles/6_SMOKE_TEST

  ->For bash installation, these are related shell scripts below:
    ./config/infra/pvs/create_pvs.sh
    ./config/infra/pvs/pvs_5Gsize.sh
    ./config/infra/pvs/pvs_10Gsize.sh
    ./config/bin/nodejs_mongo_smoke_test.sh

++ HA Requirements
  There are three masters working
  There are three etcd instances working
  There is a load balancer to access the masters called loadbalancer1.$GUID.example.opentlc.com
  There is a load balancer/DNS for both infranodes called *.apps.$GUID.example.opentlc.com
  There are at two infranodes, labeled env=infra
  ->These are the related ROLES:
    ./roles/4_INITIATE_HOSTS_FILE
    ./roles/9_HPA_CONFIG_PROD

  ->For bash installation, these are related command below:
    oc autoscale dc/os-tasks --min 1 --max 10 --cpu-percent=80 -n os-tasks-${GUID}-prod
    ./config/templates/hosts_template_ans.yaml

++ Environment Configuration
  NetworkPolicy is configured and working with projects isolated by default:
    -> os_sdn_network_plugin_name='redhat/openshift-ovs-networkpolicy'

  Aggregated logging is configured and working
  Metrics collection is configured and working
  Router and Registry Pods run on Infranodes
  Metrics and Logging components run on Infranodes
  Service Catalog, Template Service Broker, and Ansible Service Broker are all working very well.
  ->These are the related ROLES:
    ./roles/4_INITIATE_HOSTS_FILE

  ->For bash installation, these are related templates below:
    ./config/templates/hosts_template_ans.yaml

++ CICD Workflow
  Jenkins pod is running with a persistent volume
  Jenkins deploys openshift-tasks app
  Jenkins OpenShift plugin is used to create a CICD workflow
  HPA is configured and working on production deployment of openshift-tasks
  ->These are the related ROLES:
    ./roles/8_CICD_WORKFLOW

  ->For bash installation, these are related templates below:
    ./config/templates/os_pipeline_template.yaml
    ./config/templates/setup_jenkins.yaml
    ./config/infra/setup_cicd_no_ha.sh

++ Multitenancy
  Alpha Corp group have two users, amy and Andrew
  Beta Corp group have two users, brian and betty
  Omega Corp group have two users, nikola and tesla
  Dedicated node for each Client:
  ->These are the related ROLES:
    ./roles/10_MULTITENANT_ROLE
    ./roles/OPENSHIFT-APPLIER

  The new project template is modified so that it includes a LimitRange
  The new user template is used to create a user object with the specific label value
  ->These are related templates below:
    ./applier/DEPLOY-CLIENT-PROJECTS
    ./applier/MULTITENANT

++ Onboarding users
Be aware about which project the new client must be added, we have 3 projects ALPHA, BETA and OMEGA(common).
In the case you need a new project, check ./applier/DEPLOY-CLIENT-PROJECTS/PARAMS folder.
To onboard new client, the following steps are required.
1. Create users
  # oc process user-request-template -p CLIENT_LABEL_KEY="client" -p CLIENT_LABEL_VALUE="alpha" -p USER_NAME=amy | oc create -f -
  # oc process user-request-template -p CLIENT_LABEL_KEY="client" -p CLIENT_LABEL_VALUE="alpha" -p USER_NAME=andrew | oc create -f -
2. Create group
  # oc process multitenant-project-request -p PROJECT_DESCRIPTION='' -p PROJECT_DISPLAYNAME='' -p PROJECT_NAME='alpha' -p PROJECT_ADMIN_USER='amy' -p GROUP_NAME=alpha-users -p CLIENT_NODE_SELECTOR='client=alpha' | oc create -f -
3. Create Projects
  # oc process group-request-template -p GROUP_NAME=alpha-users -p GROUP_USERS='["amy","andrew"]' | oc create -f -
